---
title: "zab协议流程"
date: 2025-07-23
author: cimaStone
category: "技术架构/zab协议流程"
tags: 
  - 技术架构
  - zab协议
---
# zab协议流程

## 🎯 背景
zab协议主要是zookeeper完成选举和日志同步协议两部分

## 📖 流程
### Zookeeper选举机制
#### 概述
Zookeeper集群由多个服务器节点组成，其中一个为Leader，其他为Follower（还有Observer）。Leader负责处理写请求和事务性操作，Follower主要负责处理读请求，Observer仅同步数据不参与选举。

**为什么需要选举？**
 - 保证集群只有一个Leader。
 - Leader挂掉后，能自动选出新的Leader。
 - 保证分布式一致性。

#### 选举过程的阶段
Zookeeper的选举算法经历过几次迭代，主要有：Basic Majority Vote、**Fast Leader Election（FLE）**等。以FLE为例，选举过程可以分为两个阶段：

1. 第一阶段：提名与投票
  - 每个节点启动后，都会认为自己是Leader候选人。
  - 节点广播自己的投票，包括：节点ID、事务ID（zxid）、任期（epoch）。
  - 每个节点收到其他节点的投票后，比较投票优先级（优先级规则：epoch > zxid > serverId）。
  - 节点投票给优先级最高的候选人（包括自己）。正常来说第一阶段完成时，应该是所有的投票都指向同一个节点

2. 第二阶段：收敛与确认
  - 当某个节点收到过半数（n/2+1）节点的投票支持自己时，会宣布自己为Leader。
  - 其他节点一旦收到“自己支持的候选人”成为Leader的消息，也切换为Follower，并完成与Leader的同步。
  - 选举结束，进入正常工作状态。

#### 选举算法举例（Fast Leader Election）
设有 5 个节点：A, B, C, D, E假定每个节点有如下属性：
  - myid：节点唯一编号
  - zxid：事务ID（越大越新，优先级越高）
  - epoch：轮次（任期）
    
假设初始状态如下：
| 节点 | myid | zxid | epoch |
| :---: | :---: | :---: | :---: |
| A | 1 | 10 | 0 |
| B | 2 | 20 | 0 |
| C | 3 | 15 | 0 |
| D | 4 | 18 | 0 |
| E | 5 | 17 | 0 |

##### 初次leader选举
**第一阶段：提名和投票**
1. 节点启动，自认为Leader，广播投票  
   每个节点都向集群广播自己的选票（myid, zxid, epoch）。   
   例如：
    - A投票：1, 10, 0
    - B投票：2, 20, 0
    - C投票：3, 15, 0
    - D投票：4, 18, 0
    - E投票：5, 17, 0

2. 收到其他节点投票，比较优先级，决定投票对象  
  优先级规则：epoch > zxid > myid
  这里所有节点epoch都为0，比较zxid：
    - B的zxid最大（20），所以其他节点都把投票改为支持B。

3. 节点修改自己的投票
   - A收到B投票后，发现B更优，把自己的投票改为支持B。
   - C、D、E同理。
     
此时所有节点的投票都变成：
  - 投票给B（myid=2, zxid=20, epoch=0）

> 这里补充说明，第一阶段可能发生了多轮投票，每次收到更优的投票，都会重新发起投票，把自己的“投票人”改成当前最优的那个节点，并广播出去。以节点A来说：
> - A节点投票1, 10, 0；监听到C投票3, 15, 0；
> - 发起第二轮投票3, 15, 0，监听到E投票5, 17, 0
> - 发起第三轮投票5, 17, 0，监听到B投票2, 20, 0
> - 发起第四轮投票2, 20, 0

**第二阶段：收敛与确认**
1. 统计投票结果
   B节点发现自己获得了超过半数（3/5）节点的支持。  

2. B宣布自己当选Leader，B节点广播自己成为Leader的消息。

3. 其他节点收到Leader宣布后，切换为Follower
节点A、C、D、E收到B的Leader确认消息后，进入Follower状态，并与Leader同步数据。

4. 选举结束，集群进入工作状态

##### leader down机，再次选举的过程
1. 经过上一轮选举后，B为leader，B节点突然down，此时需要分为两种状态，日志是否有同步，先举简单例子，日志都已同步时的各节点中的各元素值
| 节点 | myid | zxid | epoch |
| :---: | :---: | :---: | :---: |
| A | 1 | 20 | 0 |
| B | 2 | 20 | 0 |
| C | 3 | 20 | 0 |
| D | 4 | 20 | 0 |
| E | 5 | 20 | 0 |

2. B节点down机，通过心跳机制和超时机制，follow节点发现B节点down机，B、C、D、E都会发起新的一轮选举，当然会有先后，举例E节点开始发起新的选举
   - 将epoch + 1处理，向集群内A、C、D节点发起投票
   - A、C、D节点根据是否检测到leader down做以下处理
     - 检测到leader down时，epoch + 1进行广播自身节点
     - 未检测到leader down时，但收到E节点广播，发现epoch == 1，此时不需要等待超时，直接将自己节点的epoch == E节点广播的epoch值，广播自身节点
   - 按照epoch > zxid > myid规则进行第一阶段投票，最终会收敛为E节点为leader节点，只需要经过一轮投票则能快速的选举出新leader

##### 日志同步，leader down机再选举过程
1. E节点为leader，此时处理了多次请求，zxid不断累积，并同步至其它follow，同时B节点恢复，当前所有节点的各元素值
| 节点 | myid | zxid | epoch |
| :---: | :---: | :---: | :---: |
| A | 1 | 30 | 1 |
| B | 2 | 20 | 0 |
| C | 3 | 30 | 1 |
| D | 4 | 30 | 1 |
| E | 5 | 30 | 1 |
2. B节点重启后，会从E节点同步数据，最终zxid和epoch都会更新至与leader一致，此时E节点再次接收到外部请求
   

--- 

#### 异常场景
1. 网络分区导致无法选出Leader  

**场景举例：**  
假设有5个节点：A, B, C, D, E。
发生网络分区，A、B、C在一个分区，D、E在另一个分区。
假如A、B、C分区开始选举，最优节点C获得A和B的投票，但只有3票，不足半数（需要3/5+1=4票），所以无法选出Leader。  

**应对方式：**  
Zookeeper要求必须有多数节点（Quorum）才能选出Leader，没有多数派则无法完成选举，这样可以防止脑裂（双Leader）现象。

---

2. 网络分区导致双Leader（脑裂）

**场景举例：**  
假设有7个节点，分为4/3分区：A, B, C, D在一组，E, F, G在另一组。
如果网络异常，两个分区都各自有超过半数节点（比如有bug或配置错误），可能各自选出Leader，这就是“双Leader”或“脑裂”现象。

**应对方式：**  
Zookeeper设计时严格要求只有一个分区能达成Quorum并选出Leader，另一个分区无法达成Quorum只能成为Follower或Observer，防止双Leader。但如果实现有bug或网络极端异常，理论上还是有脑裂风险。

---

3. 节点频繁宕机或重启，选举一直无法收敛

**场景举例：**  
5个节点，不断有节点重启或崩溃，比如刚刚凑够半数投票，某个节点又宕机或重新启动，投票又要重新发起，选举过程一直无法结束。

**应对方式：**  
Zookeeper有超时机制，选举超过限定时间会重试，直到集群稳定为止。如果节点一直波动，集群就无法进入稳定状态。

---

4. 消息延迟或乱序导致选举异常

**场景举例：**  
节点A收到B的投票后改为支持B，但由于网络延迟，A的旧投票又被其它节点收集并投给了A，导致投票混乱或反复切换，选举过程变慢。

**应对方式：**  
Zookeeper协议有epoch（轮次）机制，每轮选举会递增epoch，旧轮次的投票会被忽略，可以最终收敛。

---

5. 节点恶意作恶（拜占庭异常）

**场景举例：**  
某个节点恶意广播虚假投票、伪造选举数据，导致其它节点被误导，选举无法达成一致或出现异常Leader。

**应对方式：**  
Zookeeper不防拜占庭攻击，只防止普通故障，如果有节点作恶，确实可能导致异常，这也是Zookeeper不适用于区块链/高安全场景的原因。

---

6. 集群配置错误

**场景举例：**  
配置文件错误，导致各节点认为集群规模不同（比如有的认为是5节点，有的认为是7节点），投票规则不一致，选举无法进行。

**应对方式：**  
集群必须配置一致，Zookeeper启动时会校验配置，否则会拒绝启动。

---
**总结**

Zookeeper主要异常选举场景：
  - 网络分区导致无法获得多数派，无法选出Leader。
  - 网络极端分区或实现Bug导致脑裂（双Leader）。
  - 节点频繁宕机或重启，选举过程一直无法收敛。
  - 网络延迟或消息乱序导致选举周期长或反复。
  - 拜占庭（恶意节点）异常，Zookeeper无法防御。
  - 配置不一致导致投票规则混乱。

**绝大多数情况下，Zookeeper能通过Quorum和epoch机制防止双Leader，只要网络和配置正常，最终能收敛选举。**

---

#### 概念定义
1. Quorum（多数派）在Zookeeper中的定义
   - Zookeeper采用Quorum机制，多数派=集群节点数的半数以上。
   - 如果有5个节点：A、B、C、D、E。半数以上是3票（因为5/2=2.5，向上取整为3）。
通过Quorum（多数派）机制防止网络分区时的脑裂场景，只允许多数派的分区选Leader，少数派的分区只能等待恢复通信。如果你看到“两个分区都能选Leader”这种说法，通常指的是理论上如果协议实现有问题或者集群配置不合理时才会出现，正常情况下Zookeeper不会这样

2. 什么是epoch？
   - epoch（又叫term、轮次、时期）用来标记选举或协议推进的“轮数”。
   - 每当开始新一轮选举或发生重大变更时，epoch就会+1。
   - epoch越大，代表越“新”的一轮，优先级高。

3. 如何判断老Leader down机？
  Zookeeper等分布式系统通常采用心跳机制和超时检测来判断Leader是否存活：
    - 心跳机制：Follower节点会定期向Leader发送心跳包，或者Leader定期向Follower发送心跳包。
    - 超时检测：如果在某个超时时间（如 sessionTimeout）内没有收到Leader的心跳/响应，Follower就认为Leader已经失效（Down机、网络不可达等）。

  详细流程举例：
    - 节点A是Leader，节点B/C/D/E是Follower。
    - B、C、D、E持续等待A的心跳。
    - 如果B在超时时间内（比如2秒、5秒）没有收到A的心跳，就判断A已不可用。
    - 一旦检测到Leader不可用，B就会触发新一轮选举。

